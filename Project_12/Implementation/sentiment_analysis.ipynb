{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5d7c8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "from boruta import BorutaPy as boruta\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from numpy import *\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962c185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d42cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Details/dataset/SentimentbasedRecoEngine/sample30.csv', index_col=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "be757cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n",
      "271\n",
      "270\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "print(data['manufacturer'].nunique())\n",
    "print(data['name'].nunique())\n",
    "print(data['categories'].nunique())\n",
    "print(data['brand'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "66ba1231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29936 entries, 0 to 29999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   id                    29936 non-null  object\n",
      " 1   brand                 29936 non-null  object\n",
      " 2   categories            29936 non-null  object\n",
      " 3   manufacturer          29795 non-null  object\n",
      " 4   name                  29936 non-null  object\n",
      " 5   reviews_date          29896 non-null  object\n",
      " 6   reviews_didPurchase   15931 non-null  object\n",
      " 7   reviews_doRecommend   27395 non-null  object\n",
      " 8   reviews_rating        29936 non-null  int64 \n",
      " 9   reviews_text          29936 non-null  object\n",
      " 10  reviews_title         29747 non-null  object\n",
      " 11  reviews_userCity      1900 non-null   object\n",
      " 12  reviews_userProvince  166 non-null    object\n",
      " 13  reviews_username      29936 non-null  object\n",
      " 14  user_sentiment        29936 non-null  object\n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data[(data['reviews_username'].isnull()==False) & (data['user_sentiment'].isnull()==False)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba2d15fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    26579\n",
       "Negative     3357\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d8bd1ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b8bcc82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_sentiment  reviews_doRecommend\n",
       "Negative        False                    556\n",
       "                True                    2380\n",
       "Positive        False                    994\n",
       "                True                   23465\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['user_sentiment', 'reviews_doRecommend'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0896caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29936, 12)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['id', 'brand', 'categories', 'manufacturer', 'name', 'reviews_date', 'reviews_text', 'reviews_title', 'reviews_doRecommend',\n",
    "         'reviews_rating', 'reviews_username', 'user_sentiment']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fbe76962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "brand                     0\n",
       "categories                0\n",
       "manufacturer            141\n",
       "name                      0\n",
       "reviews_date             40\n",
       "reviews_text              0\n",
       "reviews_title           189\n",
       "reviews_doRecommend    2541\n",
       "reviews_rating            0\n",
       "reviews_username          0\n",
       "user_sentiment            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f71cd1a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "df['reviews_title'] = df['reviews_title'].astype('O')\n",
    "cnt = [i for i in df['reviews_title'].to_list() if isinstance(i, float)]\n",
    "print(cnt)\n",
    "cnt = [i for i in df['reviews_text'].to_list() if i.isnumeric()]\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7e639306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_title'] = df['reviews_title'].fillna('NF')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0e05ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.loc[i,'reviews_title'] == 'NF':\n",
    "        if df.loc[i, 'user_sentiment'] == 'Positive':\n",
    "            df.loc[i,'reviews_title']='Good'\n",
    "        if df.loc[i, 'user_sentiment'] == 'Negative':\n",
    "            df.loc[i,'reviews_title']='Bad'\n",
    "\n",
    "df['manufacturer'].fillna(df['brand'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8705563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# add stemming and lemmatisation in the preprocess function\n",
    "def preprocess(document):\n",
    "    'changes document to lower case and removes stopwords'\n",
    "    document = document.lower()\n",
    "    words = word_tokenize(document)\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    document = \" \".join(words)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e0db3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_text'] = df['reviews_title']+' '+df['reviews_text']\n",
    "df['reviews_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4a64318c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29936, 13)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['proc_reviews_text'] = df['reviews_text'].apply(preprocess)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "74d788e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "      <th>proc_reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>Just Awesome i love this album. it's very good...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "      <td>awesom love album . 's good . hip hop side cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>Good Good flavor. This review was collected as...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good good flavor . review collect part promot .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  Just Awesome i love this album. it's very good...  Just Awesome   \n",
       "1  Good Good flavor. This review was collected as...          Good   \n",
       "\n",
       "  reviews_doRecommend  reviews_rating reviews_username user_sentiment  \\\n",
       "0                 NaN               5           joshua       Positive   \n",
       "1                 NaN               5        dorothy w       Positive   \n",
       "\n",
       "                                   proc_reviews_text  \n",
       "0  awesom love album . 's good . hip hop side cur...  \n",
       "1    good good flavor . review collect part promot .  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ddf31ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('final_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6b0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3691ca5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29936 entries, 0 to 29935\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   29936 non-null  object\n",
      " 1   brand                29936 non-null  object\n",
      " 2   categories           29936 non-null  object\n",
      " 3   manufacturer         29936 non-null  object\n",
      " 4   name                 29936 non-null  object\n",
      " 5   reviews_date         29896 non-null  object\n",
      " 6   reviews_text         29936 non-null  object\n",
      " 7   reviews_title        29936 non-null  object\n",
      " 8   reviews_doRecommend  27395 non-null  object\n",
      " 9   reviews_rating       29936 non-null  int64 \n",
      " 10  reviews_username     29936 non-null  object\n",
      " 11  user_sentiment       29936 non-null  object\n",
      " 12  proc_reviews_text    29936 non-null  object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('final_data.csv', index_col=None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ad986e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26579\n",
       "0     3357\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'] = df['user_sentiment'].map({'Positive':1, 'Negative':0})\n",
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c62003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327ab1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"awesom love album . 's good . hip hop side current pop sound .. hype ! listen everyday gym ! give 5star rate way . metaphor crazi .\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'proc_reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad95289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['proc_reviews_text'], df['user_sentiment']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['proc_reviews_text'], df['user_sentiment'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a374db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffedd7a",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "1. TF-IDF Vectorizer \n",
    "2. Bag-of-Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c133252",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_model = tfidf_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17442a6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22452, 13290)\n"
     ]
    }
   ],
   "source": [
    "xtrain_tfi = tfidf_model.transform(xtrain)\n",
    "xtest_tfi  = tfidf_model.transform(xtest)\n",
    "\n",
    "xdf_tf = pd.DataFrame(xtrain_tfi.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "print(xdf_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a493c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22b28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow_model = bow_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e27934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22452, 13076)\n"
     ]
    }
   ],
   "source": [
    "xtrain_bow = bow_model.transform(xtrain)\n",
    "xtest_bow  = bow_model.transform(xtest)\n",
    "\n",
    "xdf_bow = pd.DataFrame(xtrain_bow.toarray(), columns=bow_vectorizer.get_feature_names())\n",
    "print(xdf_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47965f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22452, 13290), (7484, 13290), (22452, 13076), (7484, 13076))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfi.shape, xtest_tfi.shape, xtrain_bow.shape, xtest_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1139c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54158010",
   "metadata": {},
   "source": [
    "## Class Imbalance Fix\n",
    "1. TF-IDF features\n",
    "2. Bag-of-Words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4933d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_train_tf, y_train_tf = oversample.fit_resample(xtrain_tfi, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c9c10ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    19937\n",
       " 1    19937\n",
       " Name: user_sentiment, dtype: int64,\n",
       " (39874, 13290))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf.value_counts(), x_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae5bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea2a74b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_train_bw, y_train_bw = oversample.fit_resample(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c63333c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    19937\n",
       " 1    19937\n",
       " Name: user_sentiment, dtype: int64,\n",
       " (39874, 13076))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bw.value_counts(), x_train_bw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87f8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4326d1b",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "1. TF-IDF\n",
    "2. Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe8ccd",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58fadb3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(penalty=\"l2\", random_state=42, C=3.5)\n",
    "logreg1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train = logreg1.predict(x_train_tf)\n",
    "pred_test  = logreg1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22515775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     20838\n",
      "           1       0.92      0.96      0.94     19024\n",
      "\n",
      "    accuracy                           0.94     39862\n",
      "   macro avg       0.94      0.94      0.94     39862\n",
      "weighted avg       0.94      0.94      0.94     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.45      0.56      1396\n",
      "           1       0.88      0.97      0.92      6088\n",
      "\n",
      "    accuracy                           0.87      7484\n",
      "   macro avg       0.82      0.71      0.74      7484\n",
      "weighted avg       0.86      0.87      0.86      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afe27fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701229289150187 0.7087261708881014\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test, ytest), roc_auc_score(pred_test, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362c84a",
   "metadata": {},
   "source": [
    "Old: Train accuracy: 0.8899546647578144 . Test accuracy: 0.8838659392049883\n",
    "Train AUC: 0.9449458052810008. Test AUC: 0.5255060352831941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268e720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cd4750c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(penalty=\"l2\", random_state=42, C=3.5)\n",
    "logreg2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train2 = logreg2.predict(x_train_bw)\n",
    "pred_test2  = logreg2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "531b0a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     20036\n",
      "           1       0.96      0.97      0.97     19826\n",
      "\n",
      "    accuracy                           0.97     39862\n",
      "   macro avg       0.97      0.97      0.97     39862\n",
      "weighted avg       0.97      0.97      0.97     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.51      0.58      1076\n",
      "           1       0.92      0.96      0.94      6408\n",
      "\n",
      "    accuracy                           0.89      7484\n",
      "   macro avg       0.79      0.73      0.76      7484\n",
      "weighted avg       0.88      0.89      0.89      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08e235a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892036344200962 0.7343457759584905\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test2, ytest), roc_auc_score(pred_test2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a66aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16968f09",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef875c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb1 = BernoulliNB()\n",
    "bnb1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_nb1 = bnb1.predict(x_train_tf)\n",
    "pred_test_nb1  = bnb1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2336a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76     15055\n",
      "           1       0.91      0.73      0.81     24807\n",
      "\n",
      "    accuracy                           0.79     39862\n",
      "   macro avg       0.79      0.81      0.79     39862\n",
      "weighted avg       0.82      0.79      0.79     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.29      0.30       935\n",
      "           1       0.90      0.91      0.91      6549\n",
      "\n",
      "    accuracy                           0.84      7484\n",
      "   macro avg       0.61      0.60      0.61      7484\n",
      "weighted avg       0.83      0.84      0.83      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_nb1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_nb1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be991317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835515766969535 0.6011723225083145\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_nb1, ytest), roc_auc_score(pred_test_nb1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5962232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3427a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb2 = BernoulliNB()\n",
    "bnb2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_nb2 = bnb2.predict(x_train_bw)\n",
    "pred_test_nb2  = bnb2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "454c685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86     22807\n",
      "           1       0.78      0.91      0.84     17055\n",
      "\n",
      "    accuracy                           0.85     39862\n",
      "   macro avg       0.85      0.86      0.85     39862\n",
      "weighted avg       0.86      0.85      0.85     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.20      0.29      2029\n",
      "           1       0.76      0.92      0.83      5455\n",
      "\n",
      "    accuracy                           0.73      7484\n",
      "   macro avg       0.62      0.56      0.56      7484\n",
      "weighted avg       0.69      0.73      0.68      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_nb2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_nb2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c3c0fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272848743987173 0.5626644181820071\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_nb2, ytest), roc_auc_score(pred_test_nb2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e9fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5853b46d",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38ff411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier()\n",
    "xgb1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_xg1 = xgb1.predict(x_train_tf)\n",
    "pred_test_xg1  = xgb1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366154d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     19914\n",
      "           1       0.95      0.95      0.95     19960\n",
      "\n",
      "    accuracy                           0.95     39874\n",
      "   macro avg       0.95      0.95      0.95     39874\n",
      "weighted avg       0.95      0.95      0.95     39874\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.54      1013\n",
      "           1       0.92      0.95      0.93      6471\n",
      "\n",
      "    accuracy                           0.88      7484\n",
      "   macro avg       0.76      0.72      0.74      7484\n",
      "weighted avg       0.88      0.88      0.88      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_xg1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_xg1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5399073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8849545697487974 0.7186535630223871\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_xg1, ytest), roc_auc_score(pred_test_xg1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929964d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fc94162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier()\n",
    "xgb2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_xg2 = xgb2.predict(x_train_bw)\n",
    "pred_test_xg2  = xgb2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e56b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     19119\n",
      "           1       0.98      0.94      0.96     20755\n",
      "\n",
      "    accuracy                           0.96     39874\n",
      "   macro avg       0.96      0.96      0.96     39874\n",
      "weighted avg       0.96      0.96      0.96     39874\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.66      0.53       561\n",
      "           1       0.97      0.93      0.95      6923\n",
      "\n",
      "    accuracy                           0.91      7484\n",
      "   macro avg       0.70      0.79      0.74      7484\n",
      "weighted avg       0.93      0.91      0.92      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_xg2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_xg2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41fe6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111437733832175 0.7947155146643636\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_xg2, ytest), roc_auc_score(pred_test_xg2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbdc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a032bd5",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2ad05734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier()\n",
    "rf1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_rf1 = rf1.predict(x_train_tf)\n",
    "pred_test_rf1  = rf1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45f3eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19933\n",
      "           1       1.00      1.00      1.00     19929\n",
      "\n",
      "    accuracy                           1.00     39862\n",
      "   macro avg       1.00      1.00      1.00     39862\n",
      "weighted avg       1.00      1.00      1.00     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.56      0.46       576\n",
      "           1       0.96      0.93      0.94      6908\n",
      "\n",
      "    accuracy                           0.90      7484\n",
      "   macro avg       0.68      0.75      0.70      7484\n",
      "weighted avg       0.92      0.90      0.91      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_rf1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_rf1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01915737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981827899518974 0.74513195248665\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_rf1, ytest), roc_auc_score(pred_test_rf1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d7506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b72709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier()\n",
    "rf2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_rf2 = rf2.predict(x_train_bw)\n",
    "pred_test_rf2  = rf2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "42c0855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19941\n",
      "           1       1.00      1.00      1.00     19921\n",
      "\n",
      "    accuracy                           1.00     39862\n",
      "   macro avg       1.00      1.00      1.00     39862\n",
      "weighted avg       1.00      1.00      1.00     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54       829\n",
      "           1       0.94      0.94      0.94      6655\n",
      "\n",
      "    accuracy                           0.90      7484\n",
      "   macro avg       0.74      0.74      0.74      7484\n",
      "weighted avg       0.90      0.90      0.90      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_rf2, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_rf2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f024d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8972474612506681 0.7410540520700127\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_rf2, ytest), roc_auc_score(pred_test_rf2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b36ca83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4e443",
   "metadata": {},
   "source": [
    "{'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': 'auto',\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd832889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de4c42ea",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "1. XGBoost with bag of words feature extraction performs best among all 4 models\n",
    "2. The model's performance can be improved using feature selection/dimensionality reduction on the data and hyperparameter optimization of the model\n",
    "\n",
    "#### Saving XGBoost Model and Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "834d6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vect = \"tfidf_vect.pkl\"\n",
    "# with open(tfidf_vect, 'wb') as file:\n",
    "#     pickle.dump(tfidf_vectorizer, file)\n",
    "\n",
    "# pkl_filename = \"tfidf_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(tfidf_model, file)\n",
    "    \n",
    "# pkl_filename = \"bow_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(bow_model, file)\n",
    "    \n",
    "# bow_vect = \"bow_vect.pkl\"\n",
    "# with open(bow_vect, 'wb') as file:\n",
    "#     pickle.dump(bow_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc75deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_filename = \"xgb_tf_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(xgb1, file)\n",
    "\n",
    "# pkl_filename = \"xgb_bow_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(xgb2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29032880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc6e0e2",
   "metadata": {},
   "source": [
    "## Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51e2ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_file = \"tfidf_model.pkl\"\n",
    "with open(tf_model_file, 'rb') as file:\n",
    "    tf_model = pickle.load(file)\n",
    "    \n",
    "xgtf_model_file = \"xgb_tf_model.pkl\"\n",
    "with open(xgtf_model_file, 'rb') as file:\n",
    "    xgtf_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2387ee40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7472751 , 0.25272486]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some = tf_model.transform(xtrain[1200:1201].to_list())\n",
    "xgtf_model.predict_proba(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca76101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27203    0\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[1200:1201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e8ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12800536",
   "metadata": {},
   "source": [
    "## Hyper-parameter Optimization:\n",
    "- XGBoost (Best Performing Model)\n",
    "- Prevent Overfitting (Using Random Search with Cross Validation & PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb62435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# max_depth = [int(x) for x in np.linspace(10, 100, num=10)]\n",
    "# max_depth.append(None)\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e8d5b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=30, scoring='accuracy', \n",
    "#                       cv=3, verbose=2, random_state=42, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "656b5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fa151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f429ea43",
   "metadata": {},
   "source": [
    "## Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3f8d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joshua</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rebecca</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walker557</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviews_username                                        name  \\\n",
       "0           joshua   Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1        dorothy w  Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "2        dorothy w  Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "3          rebecca            K-Y Love Sensuality Pleasure Gel   \n",
       "4        walker557            K-Y Love Sensuality Pleasure Gel   \n",
       "\n",
       "   reviews_rating              reviews_date  \n",
       "0               5  2012-11-30T06:21:45.000Z  \n",
       "1               5  2017-07-09T00:00:00.000Z  \n",
       "2               5  2017-07-09T00:00:00.000Z  \n",
       "3               1  2016-01-06T00:00:00.000Z  \n",
       "4               1  2016-12-21T00:00:00.000Z  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = df[['reviews_username', 'name', 'reviews_rating', 'reviews_date']]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b9b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29936 entries, 0 to 29935\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   reviews_username  29936 non-null  object\n",
      " 1   name              29936 non-null  object\n",
      " 2   reviews_rating    29936 non-null  int64 \n",
      " 3   reviews_date      29896 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 935.6+ KB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "272d4a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24914, 271)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['reviews_username'].nunique(), ratings['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af93902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     271.000000\n",
       "mean      110.317343\n",
       "std       585.800600\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         8.000000\n",
       "75%        29.000000\n",
       "max      8525.000000\n",
       "Name: reviews_date, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating = ratings.groupby(['name'])['reviews_date'].count().reset_index()\n",
    "min_movie_rating['reviews_date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7cbc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861.8000000000006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(min_movie_rating['reviews_date'], 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231502d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65    Clorox Disinfecting Wipes Value Pack Scented 1...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating[min_movie_rating['reviews_date']==8525]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34540a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating.loc[65, 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f63ad21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8525, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings['name']=='Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37ac7b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42 Dual Drop Leaf Table with 2 Madrid Chairs\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5302050 15/16 FCT/HOSE ADAPTOR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Avery174 11-1/4 X 9-1/4 Index Maker Extra Wide...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Black Sister's Revenge (dvd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Blue Anchor Design Throw Pillow (18x18) - Rizz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bodycology Nourishing Body Cream, Pretty In Paris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Cal Lighting Led Dark Bronze Finish Metal Pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Candy Pink Plastic Cups, 20 pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Carson-Dellosa Publishing Photographic Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Citrus Magic Instant Spot &amp; Stain Remover</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Clorox Ultimate Care Premium Bleach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Craft Punch Giga Scallop Circle 45 24687534 To...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Disney174 Jake And The Neverland Pirates 4 Pie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Elvis Presley - Girl Happy (cd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Every Man Jack Pomade Signature Mint Scent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Fantasy Fields Lil' Sports Fan Step Stool - Te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Germ Guardian174 Elite 3-In-1 Pet Pure True He...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Greyson Vintage Industrial Occasional Cocktail...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heinz Tomato Ketchup, 38oz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Herr's Baked Cheese Curls</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>High-Dome Floor Door Stop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Home Health Hairever Shampoo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Iman Luxury Moisturizing Lipstick, Black Brand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>JNH Lifestyles Goldstar 3 Person FAR Infrared ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Kenroy Home Table Lamp - Chrome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>La Tortilla Factory Hand Made Style Tortillas ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Lite Source Basic Ii 1-Lt Floor Lamp - Dark Br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Lite Source Reiko 1 Light Table Lamp - Orange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Noosa Honey Yogurt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Pacific Natural Foods Organic Beef Broth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Pearhead Id Bracelet Frame</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Pocket Watch Wall Clock Distressed Black - Yos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Progresso Traditional Chicken Rice With Vegeta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Progresso Traditional Meatball &amp; Rice Soup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Roommates No Place Like Home Peel Stick Wall D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Scotty Mini Double Ended Extender</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Sea Gull Lighting Ceiling Fan - White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Sea Gull Lighting One Light Wall/bath/vanity-B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Sloan Royal Urinal Flush Valve, 1.0 Gpf, Royal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Southern Enterprises Archer Fold-Away Home Bar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Stonyfield Yobaby Peach &amp; Pear Yogurt 4oz 6 Ct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Sunflower Swag With Metal Frame - Nearly Natural</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Tostitos Original Restaurant Style Tortilla Chips</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Udi's Pepperoni Pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Various - Country's Greatest Gospel:Gold Ed (cd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Walkers Stem Ginger Shortbread</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Wallmount Server Cabinet (450mm, 9 RU)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Wedding Wishes Wedding Guest Book</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Wilton Black Dots Standard Baking Cups</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  reviews_date\n",
       "4        42 Dual Drop Leaf Table with 2 Madrid Chairs\"             1\n",
       "6                       5302050 15/16 FCT/HOSE ADAPTOR             0\n",
       "18   Avery174 11-1/4 X 9-1/4 Index Maker Extra Wide...             1\n",
       "35                        Black Sister's Revenge (dvd)             1\n",
       "36   Blue Anchor Design Throw Pillow (18x18) - Rizz...             1\n",
       "37   Bodycology Nourishing Body Cream, Pretty In Paris             1\n",
       "43   Cal Lighting Led Dark Bronze Finish Metal Pian...             1\n",
       "45                      Candy Pink Plastic Cups, 20 pk             1\n",
       "50   Carson-Dellosa Publishing Photographic Learnin...             1\n",
       "61           Citrus Magic Instant Spot & Stain Remover             1\n",
       "66                 Clorox Ultimate Care Premium Bleach             1\n",
       "72   Craft Punch Giga Scallop Circle 45 24687534 To...             1\n",
       "80   Disney174 Jake And The Neverland Pirates 4 Pie...             1\n",
       "83                     Elvis Presley - Girl Happy (cd)             1\n",
       "85          Every Man Jack Pomade Signature Mint Scent             1\n",
       "86   Fantasy Fields Lil' Sports Fan Step Stool - Te...             1\n",
       "92   Germ Guardian174 Elite 3-In-1 Pet Pure True He...             1\n",
       "94   Greyson Vintage Industrial Occasional Cocktail...             1\n",
       "99                          Heinz Tomato Ketchup, 38oz             1\n",
       "101                          Herr's Baked Cheese Curls             1\n",
       "102                          High-Dome Floor Door Stop             1\n",
       "105                       Home Health Hairever Shampoo             1\n",
       "110  Iman Luxury Moisturizing Lipstick, Black Brand...             1\n",
       "114  JNH Lifestyles Goldstar 3 Person FAR Infrared ...             1\n",
       "122                    Kenroy Home Table Lamp - Chrome             1\n",
       "134  La Tortilla Factory Hand Made Style Tortillas ...             1\n",
       "137  Lite Source Basic Ii 1-Lt Floor Lamp - Dark Br...             1\n",
       "138      Lite Source Reiko 1 Light Table Lamp - Orange             1\n",
       "167                                 Noosa Honey Yogurt             1\n",
       "174           Pacific Natural Foods Organic Beef Broth             1\n",
       "177                         Pearhead Id Bracelet Frame             1\n",
       "182          Pink Friday: Roman Reloaded Re-Up (w/dvd)             1\n",
       "189  Pocket Watch Wall Clock Distressed Black - Yos...             1\n",
       "193  Progresso Traditional Chicken Rice With Vegeta...             1\n",
       "195         Progresso Traditional Meatball & Rice Soup             1\n",
       "203  Roommates No Place Like Home Peel Stick Wall D...             1\n",
       "207                  Scotty Mini Double Ended Extender             0\n",
       "208              Sea Gull Lighting Ceiling Fan - White             1\n",
       "210  Sea Gull Lighting One Light Wall/bath/vanity-B...             1\n",
       "215  Sloan Royal Urinal Flush Valve, 1.0 Gpf, Royal...             1\n",
       "223  Southern Enterprises Archer Fold-Away Home Bar...             1\n",
       "231     Stonyfield Yobaby Peach & Pear Yogurt 4oz 6 Ct             1\n",
       "234   Sunflower Swag With Metal Frame - Nearly Natural             1\n",
       "245  Tostitos Original Restaurant Style Tortilla Chips             1\n",
       "252                              Udi's Pepperoni Pizza             1\n",
       "253   Various - Country's Greatest Gospel:Gold Ed (cd)             1\n",
       "261                     Walkers Stem Ginger Shortbread             1\n",
       "262             Wallmount Server Cabinet (450mm, 9 RU)             1\n",
       "265                  Wedding Wishes Wedding Guest Book             1\n",
       "267             Wilton Black Dots Standard Baking Cups             1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating[min_movie_rating['reviews_date']<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5b5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21237e48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joshua',\n",
       " 'joshv',\n",
       " 'joshbart37',\n",
       " 'josh',\n",
       " 'joshr',\n",
       " 'josh4416',\n",
       " 'omyjosh',\n",
       " 'josh6918',\n",
       " 'joshua54354354351',\n",
       " 'joshandles',\n",
       " 'joshy',\n",
       " 'byjosh',\n",
       " 'joshuam02',\n",
       " 'joshc',\n",
       " 'joshweber04',\n",
       " 'josh3110',\n",
       " 'joshua21',\n",
       " 'joshjordan']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in ratings['reviews_username'].unique() if 'josh' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b2b856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24914.000000\n",
       "mean         1.199968\n",
       "std          0.771844\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max         41.000000\n",
       "Name: reviews_date, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_user_rating = ratings.groupby(['reviews_username'])['reviews_date'].count().reset_index()\n",
    "min_user_rating['reviews_date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f67951d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(min_user_rating['reviews_date'], 95), np.percentile(min_user_rating['reviews_date'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77778caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='reviews_date'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(min_user_rating['reviews_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17342723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_user_rating[min_user_rating['reviews_date']>=3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad64dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c4c613",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11440</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6974</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6974</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19327</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24205</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating              reviews_date\n",
       "0   11440      182       5  2012-11-30T06:21:45.000Z\n",
       "1    6974      140       5  2017-07-09T00:00:00.000Z\n",
       "2    6974      140       5  2017-07-09T00:00:00.000Z\n",
       "3   19327      120       1  2016-01-06T00:00:00.000Z\n",
       "4   24205      120       1  2016-12-21T00:00:00.000Z"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings.rename(columns={'reviews_username':'userId', 'name':'movieId', 'reviews_rating':'rating'})\n",
    "\n",
    "le_usr = LabelEncoder()\n",
    "le_usr = le_usr.fit(ratings['userId'])\n",
    "ratings['userId'] = le_usr.transform(ratings['userId'])\n",
    "\n",
    "le_name = LabelEncoder()\n",
    "le_name = le_name.fit(ratings['movieId'])\n",
    "ratings['movieId'] = le_name.fit_transform(ratings['movieId'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12e5e32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>24909</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-02T00:53:21.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12732</th>\n",
       "      <td>24909</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-02T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating              reviews_date\n",
       "9103    24909       65       5  2014-12-02T00:53:21.000Z\n",
       "12732   24909       65       5  2014-12-02T00:00:00.000Z"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings['userId']==24909]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5597eaec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zxcsdfd'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_usr.inverse_transform([24909])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000c2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3771662c",
   "metadata": {},
   "source": [
    "## User-User Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "934ba214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20955, 4), (8981, 4))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(ratings, test_size=0.30, random_state=42)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd876d5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0    1    2    3    4    5    6    7    8    9    ...  260  261  262  \\\n",
       "userId                                                     ...                  \n",
       "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "movieId  263  264  265  266  268  269  270  \n",
       "userId                                      \n",
       "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 256 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = train.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "df_pivot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2c04303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0    1    2    3    4    5    6    7    8    9    ...  260  261  262  \\\n",
       "userId                                                     ...                  \n",
       "1        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "2        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "3        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "4        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "5        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "\n",
       "movieId  263  264  265  266  268  269  270  \n",
       "userId                                      \n",
       "1        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "5        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_train = train.copy()\n",
    "dummy_train['rating'] = dummy_train['rating'].apply(lambda x: 0 if x>=1 else 1)\n",
    "dummy_train = dummy_train.pivot_table(index='userId', columns='movieId', values='rating').fillna(1)\n",
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63545935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18273"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb0cbedd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.        0.        ... 0.        0.9486833 0.       ]\n",
      " [0.        1.        1.        ... 0.        0.        0.       ]\n",
      " [0.        1.        1.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 1.        0.        1.       ]\n",
      " [0.9486833 0.        0.        ... 0.        1.        0.       ]\n",
      " [0.        0.        0.        ... 1.        0.        1.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the User Similarity Matrix using pairwise_distance function.\n",
    "user_correlation = 1 - pairwise_distances(df_pivot, metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99d008aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18273, 18273)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a958c9",
   "metadata": {},
   "source": [
    "### Adjusted Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbe9e500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.00496628 -0.00496628 ... -0.00496628  0.9485598\n",
      "  -0.00496628]\n",
      " [-0.00496628  1.          1.         ... -0.00392157 -0.00392157\n",
      "  -0.00392157]\n",
      " [-0.00496628  1.          1.         ... -0.00392157 -0.00392157\n",
      "  -0.00392157]\n",
      " ...\n",
      " [-0.00496628 -0.00392157 -0.00392157 ...  1.         -0.00392157\n",
      "   1.        ]\n",
      " [ 0.9485598  -0.00392157 -0.00392157 ... -0.00392157  1.\n",
      "  -0.00392157]\n",
      " [-0.00496628 -0.00392157 -0.00392157 ...  1.         -0.00392157\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "mean = np.nanmean(df_pivot, axis=1)\n",
    "df_subtracted = (df_pivot.T-mean).T\n",
    "\n",
    "user_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1e55451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18273, 18273)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ea3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd46e8c",
   "metadata": {},
   "source": [
    "## Evaluation: User-User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20289533",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = test[test.userId.isin(train.userId)]\n",
    "common_user_based_matrix = common.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "user_correlation_df = pd.DataFrame(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99c01645",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df['userId'] = df_subtracted.index\n",
    "user_correlation_df.set_index('userId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcc17757",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name = common.userId.tolist()\n",
    "user_correlation_df.columns = df_subtracted.index.tolist()\n",
    "\n",
    "user_correlation_df_1 = user_correlation_df[user_correlation_df.index.isin(list_name)]\n",
    "user_correlation_df_2 = user_correlation_df_1.T[user_correlation_df_1.T.index.isin(list_name)]\n",
    "user_correlation_df_3 = user_correlation_df_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68705fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3[user_correlation_df_3<0]=0\n",
    "common_user_predicted_ratings = np.dot(user_correlation_df_3, common_user_based_matrix.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff98c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test = common.copy()\n",
    "dummy_test['rating'] = dummy_test['rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "dummy_test = dummy_test.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5b4f0bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>260</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0    1    9    10   14   15   16   17   19   20   ...  253  254  255  \\\n",
       "userId                                                     ...                  \n",
       "15       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "17       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "20       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "44       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "92       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "movieId  256  257  258  260  263  264  268  \n",
       "userId                                      \n",
       "15       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "44       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "92       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_user_predicted_ratings = np.multiply(common_user_predicted_ratings, dummy_test)\n",
    "common_user_predicted_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f898eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(feature_range=(1, 5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:400: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:401: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "X = common_user_predicted_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1be25429",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ = common.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0edbdd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.534229490238383\n"
     ]
    }
   ],
   "source": [
    "rmse = (sum(sum((common_ - y )**2))/total_non_nan)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ede7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d6b6ebe",
   "metadata": {},
   "source": [
    "## Prediction: User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1d9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratings_model(ratings):\n",
    "    df_pivot_w = ratings.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    mean = np.nanmean(df_pivot_w, axis=1)\n",
    "    df_subtracted_w = (df_pivot_w.T-mean).T\n",
    "\n",
    "    user_correlation_w = 1 - pairwise_distances(df_subtracted_w.fillna(0), metric='cosine')\n",
    "    user_correlation_w[np.isnan(user_correlation_w)] = 0\n",
    "    \n",
    "    user_correlation_w[user_correlation_w<0]=0\n",
    "    d_train = ratings.copy()\n",
    "    d_train['rating'] = d_train['rating'].apply(lambda x: 0 if x>=1 else 1)\n",
    "    d_train = d_train.pivot_table(index='userId', columns='movieId', values='rating').fillna(1)\n",
    "    \n",
    "    user_predicted_ratings2 = np.dot(user_correlation_w, df_pivot_w.fillna(0))\n",
    "    user_final_rating2 = np.multiply(user_predicted_ratings2, d_train)\n",
    "    return user_final_rating2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccea21fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# final_model = create_ratings_model(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1602914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_filename = \"user_final_rating.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(user_final_rating2, file)\n",
    "\n",
    "# user_encoding = \"user_encoding.pkl\"\n",
    "# with open(user_encoding, 'wb') as file:\n",
    "#     pickle.dump(le_usr, file)\n",
    "    \n",
    "# movie_name_encoding = \"movie_name_encoding.pkl\"\n",
    "# with open(movie_name_encoding, 'wb') as file:\n",
    "#     pickle.dump(le_name, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01438405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb333bb3",
   "metadata": {},
   "source": [
    "## Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bc67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "data = pd.read_csv('Model/sample30.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d3542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_file = \"Model/user_final_rating.pkl\"\n",
    "with open(final_model_file, 'rb') as file:\n",
    "    final_model = pickle.load(file)\n",
    "    \n",
    "user_encoding = \"Model/user_encoding.pkl\"\n",
    "with open(user_encoding, 'rb') as file:\n",
    "    le_usr = pickle.load(file)\n",
    "\n",
    "movie_name_encoding = \"Model/movie_name_encoding.pkl\"\n",
    "with open(movie_name_encoding, 'rb') as file:\n",
    "    le_name = pickle.load(file)\n",
    "    \n",
    "tfidf_vect = \"Model/tfidf_vect.pkl\"\n",
    "with open(tfidf_vect, 'rb') as file:\n",
    "    tf_vect = pickle.load(file)\n",
    "    \n",
    "tf_model_file = \"Model/tfidf_model.pkl\"\n",
    "with open(tf_model_file, 'rb') as file:\n",
    "    tf_model = pickle.load(file)\n",
    "    \n",
    "xgtf_model_file = \"Model/xgb_tf_model.pkl\"\n",
    "with open(xgtf_model_file, 'rb') as file:\n",
    "    xgtf_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba35707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b4aefe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your user name: 452\n",
      "['adpp']\n"
     ]
    }
   ],
   "source": [
    "# Take the user ID as input.\n",
    "user_input = int(input(\"Enter your user name: \"))\n",
    "print(le_usr.inverse_transform([user_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f7eaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>movie_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>Planes: Fire Rescue (2 Discs) (includes Digita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>Mike Dave Need Wedding Dates (dvd + Digital)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239</td>\n",
       "      <td>The Resident Evil Collection 5 Discs (blu-Ray)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>Red (special Edition) (dvdvideo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>My Big Fat Greek Wedding 2 (blu-Ray + Dvd + Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65</td>\n",
       "      <td>Clorox Disinfecting Wipes Value Pack Scented 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>Clorox Disinfecting Bathroom Cleaner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>244</td>\n",
       "      <td>Tostitos Bite Size Tortilla Chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>100:Complete First Season (blu-Ray)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>242</td>\n",
       "      <td>There's Something About Mary (dvd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>56</td>\n",
       "      <td>Chester's Cheese Flavored Puffcorn Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76</td>\n",
       "      <td>Dark Shadows (includes Digital Copy) (ultravio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>230</td>\n",
       "      <td>Stargate (ws) (ultimate Edition) (director's C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>268</td>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>115</td>\n",
       "      <td>Jason Aldean - They Don't Know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>Alex Cross (dvdvideo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41</td>\n",
       "      <td>Burt's Bees Lip Shimmer, Raisin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>71</td>\n",
       "      <td>Coty Airspun Face Powder, Translucent Extra Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Avery174 Ready Index Contemporary Table Of Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>119</td>\n",
       "      <td>Just For Men Touch Of Gray Gray Hair Treatment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId                                         movie_name\n",
       "0       183  Planes: Fire Rescue (2 Discs) (includes Digita...\n",
       "1       151       Mike Dave Need Wedding Dates (dvd + Digital)\n",
       "2       239     The Resident Evil Collection 5 Discs (blu-Ray)\n",
       "3       200                   Red (special Edition) (dvdvideo)\n",
       "4       157  My Big Fat Greek Wedding 2 (blu-Ray + Dvd + Di...\n",
       "5        65  Clorox Disinfecting Wipes Value Pack Scented 1...\n",
       "6        64               Clorox Disinfecting Bathroom Cleaner\n",
       "7       244                  Tostitos Bite Size Tortilla Chips\n",
       "8         1                100:Complete First Season (blu-Ray)\n",
       "9       242                 There's Something About Mary (dvd)\n",
       "10       56          Chester's Cheese Flavored Puffcorn Snacks\n",
       "11       76  Dark Shadows (includes Digital Copy) (ultravio...\n",
       "12      230  Stargate (ws) (ultimate Edition) (director's C...\n",
       "13      268  Windex Original Glass Cleaner Refill 67.6oz (2...\n",
       "14      115                     Jason Aldean - They Don't Know\n",
       "15        9                              Alex Cross (dvdvideo)\n",
       "16       41                    Burt's Bees Lip Shimmer, Raisin\n",
       "17       71  Coty Airspun Face Powder, Translucent Extra Co...\n",
       "18       19  Avery174 Ready Index Contemporary Table Of Con...\n",
       "19      119  Just For Men Touch Of Gray Gray Hair Treatment..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = final_model.loc[user_input].sort_values(ascending=False)[0:20].to_frame()\n",
    "d = d.reset_index()\n",
    "d.drop(d.columns[1], axis=1, inplace=True)\n",
    "\n",
    "movie_name = le_name.inverse_transform(d['movieId'])\n",
    "d['movie_name'] = movie_name\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d0aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae8edef9",
   "metadata": {},
   "source": [
    "## Selecting top 5 movies with positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3b65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review_pipeline(df):\n",
    "#     df['reviews_title'] = df['reviews_title'].fillna('NF')\n",
    "#     df = df.reset_index(drop=True)\n",
    "    \n",
    "#     start_ = time.time()\n",
    "#     for i in range(len(df)):\n",
    "#         if df.loc[i,'reviews_title'] == 'NF':\n",
    "#             if df.loc[i, 'user_sentiment'] == 'Positive':\n",
    "#                 df.loc[i,'reviews_title']='Good'\n",
    "#             if df.loc[i, 'user_sentiment'] == 'Negative':\n",
    "#                 df.loc[i,'reviews_title']='Bad'\n",
    "#     print(time.time()-start_)\n",
    "            \n",
    "    stemmer = PorterStemmer()\n",
    "    def preprocess(document):\n",
    "        'changes document to lower case and removes stopwords'\n",
    "        document = document.lower()\n",
    "        words = word_tokenize(document)\n",
    "        words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "        document = \" \".join(words)\n",
    "        return document\n",
    "    \n",
    "    start_ = time.time()\n",
    "#     df['reviews_text'] = df['reviews_title']+' '+df['reviews_text']\n",
    "    df['proc_reviews_text'] = df['reviews_text'].apply(preprocess)\n",
    "    print(time.time()-start_)\n",
    "    return df['proc_reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e501c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['name'].isin(d['movie_name'].to_list())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "114d4854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18073, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>Doesn't clean windows</td>\n",
       "      <td>Leaves windows with streaks, although it does ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>not what it used to be</td>\n",
       "      <td>it leaves streaks bad . i used windsheild wash...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "688  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "689  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "\n",
       "              reviews_title                                       reviews_text  \n",
       "688   Doesn't clean windows  Leaves windows with streaks, although it does ...  \n",
       "689  not what it used to be  it leaves streaks bad . i used windsheild wash...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = data[data['name'].isin(d['movie_name'].to_list())]\n",
    "filter_df = filter_df[~filter_df['reviews_text'].isnull()]\n",
    "filter_df = filter_df[['name', 'reviews_title', 'reviews_text']]\n",
    "print(filter_df.shape)\n",
    "filter_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e54fa0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.1362681388855\n",
      "(18073, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>proc_reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>Doesn't clean windows</td>\n",
       "      <td>Leaves windows with streaks, although it does ...</td>\n",
       "      <td>leav window streak , although seem work ok sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>not what it used to be</td>\n",
       "      <td>it leaves streaks bad . i used windsheild wash...</td>\n",
       "      <td>leav streak bad . use windsheild washer fluid ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "688  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "689  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "\n",
       "              reviews_title  \\\n",
       "688   Doesn't clean windows   \n",
       "689  not what it used to be   \n",
       "\n",
       "                                          reviews_text  \\\n",
       "688  Leaves windows with streaks, although it does ...   \n",
       "689  it leaves streaks bad . i used windsheild wash...   \n",
       "\n",
       "                                     proc_reviews_text  \n",
       "688  leav window streak , although seem work ok sur...  \n",
       "689  leav streak bad . use windsheild washer fluid ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df['proc_reviews_text'] = process_review_pipeline(filter_df)\n",
    "print(filter_df.shape)\n",
    "filter_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc94b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bebc5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18073, 13290)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tf_model.transform(filter_df['proc_reviews_text'])\n",
    "tf_df = pd.DataFrame(tf.toarray(), columns=tf_vect.get_feature_names())\n",
    "tf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673feffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>proc_reviews_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>Doesn't clean windows</td>\n",
       "      <td>Leaves windows with streaks, although it does ...</td>\n",
       "      <td>leav window streak , although seem work ok sur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>not what it used to be</td>\n",
       "      <td>it leaves streaks bad . i used windsheild wash...</td>\n",
       "      <td>leav streak bad . use windsheild washer fluid ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>Streaky windows</td>\n",
       "      <td>Very disappointed in this product. It leaves a...</td>\n",
       "      <td>disappoint product . leav kind streak matter m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>The New Windex Formula Leaves a Nasty Film</td>\n",
       "      <td>Windex used to be good years ago. Since they r...</td>\n",
       "      <td>windex use good year ago . sinc reformul , lon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2...</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>Having used Windex for years , I noticed in th...</td>\n",
       "      <td>use windex year , notic last year , differ res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "688  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "689  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "690  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "691  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "692  Windex Original Glass Cleaner Refill 67.6oz (2...   \n",
       "\n",
       "                                  reviews_title  \\\n",
       "688                       Doesn't clean windows   \n",
       "689                      not what it used to be   \n",
       "690                             Streaky windows   \n",
       "691  The New Windex Formula Leaves a Nasty Film   \n",
       "692                           Very Disappointed   \n",
       "\n",
       "                                          reviews_text  \\\n",
       "688  Leaves windows with streaks, although it does ...   \n",
       "689  it leaves streaks bad . i used windsheild wash...   \n",
       "690  Very disappointed in this product. It leaves a...   \n",
       "691  Windex used to be good years ago. Since they r...   \n",
       "692  Having used Windex for years , I noticed in th...   \n",
       "\n",
       "                                     proc_reviews_text  sentiment  \n",
       "688  leav window streak , although seem work ok sur...          1  \n",
       "689  leav streak bad . use windsheild washer fluid ...          1  \n",
       "690  disappoint product . leav kind streak matter m...          1  \n",
       "691  windex use good year ago . sinc reformul , lon...          1  \n",
       "692  use windex year , notic last year , differ res...          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = xgtf_model.predict_proba(tf_df)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "filter_df['sentiment'] = best_preds\n",
    "filter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babc0592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17946, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clorox Disinfecting Wipes Value Pack Scented 1...</td>\n",
       "      <td>8430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clorox Disinfecting Bathroom Cleaner</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Planes: Fire Rescue (2 Discs) (includes Digita...</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt's Bees Lip Shimmer, Raisin</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Resident Evil Collection 5 Discs (blu-Ray)</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  sentiment\n",
       "6   Clorox Disinfecting Wipes Value Pack Scented 1...       8430\n",
       "5                Clorox Disinfecting Bathroom Cleaner       2032\n",
       "13  Planes: Fire Rescue (2 Discs) (includes Digita...       1143\n",
       "3                     Burt's Bees Lip Shimmer, Raisin        873\n",
       "16     The Resident Evil Collection 5 Discs (blu-Ray)        844"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = filter_df[filter_df['sentiment']==1]\n",
    "print(final_df.shape)\n",
    "final_df = final_df.groupby('name')['sentiment'].sum().reset_index()\n",
    "final_df = final_df.sort_values(by='sentiment', ascending=False)\n",
    "final_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d865b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total',\n",
       " 'Clorox Disinfecting Bathroom Cleaner',\n",
       " 'Planes: Fire Rescue (2 Discs) (includes Digital Copy) (blu-Ray/dvd)',\n",
       " \"Burt's Bees Lip Shimmer, Raisin\",\n",
       " 'The Resident Evil Collection 5 Discs (blu-Ray)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[:5]['name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07757216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78c9c990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter_df = filter_df.groupby(['name'])['user_sentiment'].count().reset_index()\n",
    "# filter_df = filter_df.sort_values(by='user_sentiment', ascending=False)\n",
    "# filter_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00169b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
