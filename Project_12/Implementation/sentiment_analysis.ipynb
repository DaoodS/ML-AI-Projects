{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5d7c8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from boruta import BorutaPy as boruta\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962c185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d42cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Details/dataset/SentimentbasedRecoEngine/sample30.csv', index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be757cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n",
      "271\n",
      "270\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "print(data['manufacturer'].nunique())\n",
    "print(data['name'].nunique())\n",
    "print(data['categories'].nunique())\n",
    "print(data['brand'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ba1231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29936 entries, 0 to 29999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   id                    29936 non-null  object\n",
      " 1   brand                 29936 non-null  object\n",
      " 2   categories            29936 non-null  object\n",
      " 3   manufacturer          29795 non-null  object\n",
      " 4   name                  29936 non-null  object\n",
      " 5   reviews_date          29896 non-null  object\n",
      " 6   reviews_didPurchase   15931 non-null  object\n",
      " 7   reviews_doRecommend   27395 non-null  object\n",
      " 8   reviews_rating        29936 non-null  int64 \n",
      " 9   reviews_text          29936 non-null  object\n",
      " 10  reviews_title         29747 non-null  object\n",
      " 11  reviews_userCity      1900 non-null   object\n",
      " 12  reviews_userProvince  166 non-null    object\n",
      " 13  reviews_username      29936 non-null  object\n",
      " 14  user_sentiment        29936 non-null  object\n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data[(data['reviews_username'].isnull()==False) & (data['user_sentiment'].isnull()==False)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2d15fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    26579\n",
       "Negative     3357\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8bd1ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8bcc82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_sentiment  reviews_doRecommend\n",
       "Negative        False                    556\n",
       "                True                    2380\n",
       "Positive        False                    994\n",
       "                True                   23465\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['user_sentiment', 'reviews_doRecommend'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0896caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29936, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['id', 'brand', 'categories', 'manufacturer', 'name', 'reviews_text', 'reviews_title', 'reviews_doRecommend',\n",
    "         'reviews_rating', 'user_sentiment']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe76962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "brand                     0\n",
       "categories                0\n",
       "manufacturer            141\n",
       "name                      0\n",
       "reviews_text              0\n",
       "reviews_title           189\n",
       "reviews_doRecommend    2541\n",
       "reviews_rating            0\n",
       "user_sentiment            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f71cd1a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['reviews_title'] = df['reviews_title'].astype('O')\n",
    "cnt = [i for i in df['reviews_title'].to_list() if isinstance(i, float)]\n",
    "print(cnt)\n",
    "cnt = [i for i in df['reviews_text'].to_list() if i.isnumeric()]\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e639306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['reviews_title'] = df['reviews_title'].fillna('NF')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e05ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "  if df.loc[i,'reviews_title'] == 'NF':\n",
    "    if df.loc[i, 'user_sentiment'] == 'Positive':\n",
    "      df.loc[i,'reviews_title']='Good'\n",
    "    if df.loc[i, 'user_sentiment'] == 'Negative':\n",
    "      df.loc[i,'reviews_title']='Bad'\n",
    "\n",
    "df['manufacturer'].fillna(df['brand'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8705563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# add stemming and lemmatisation in the preprocess function\n",
    "def preprocess(document):\n",
    "    'changes document to lower case and removes stopwords'\n",
    "    document = document.lower()\n",
    "    words = word_tokenize(document)\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    document = \" \".join(words)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0db3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_text'] = df['reviews_title']+' '+df['reviews_text']\n",
    "df['reviews_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a64318c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29936, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['proc_reviews_text'] = df['reviews_text'].apply(preprocess)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74d788e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>user_sentiment</th>\n",
       "      <th>proc_reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>Just Awesome i love this album. it's very good...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>awesom love album . 's good . hip hop side cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>Good Good flavor. This review was collected as...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good good flavor . review collect part promot .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "\n",
       "                                         name  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  Just Awesome i love this album. it's very good...  Just Awesome   \n",
       "1  Good Good flavor. This review was collected as...          Good   \n",
       "\n",
       "  reviews_doRecommend  reviews_rating user_sentiment  \\\n",
       "0                 NaN               5       Positive   \n",
       "1                 NaN               5       Positive   \n",
       "\n",
       "                                   proc_reviews_text  \n",
       "0  awesom love album . 's good . hip hop side cur...  \n",
       "1    good good flavor . review collect part promot .  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddf31ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('final_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6b0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3691ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29936 entries, 0 to 29935\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   29936 non-null  object\n",
      " 1   brand                29936 non-null  object\n",
      " 2   categories           29936 non-null  object\n",
      " 3   manufacturer         29936 non-null  object\n",
      " 4   name                 29936 non-null  object\n",
      " 5   reviews_text         29936 non-null  object\n",
      " 6   reviews_title        29936 non-null  object\n",
      " 7   reviews_doRecommend  27395 non-null  object\n",
      " 8   reviews_rating       29936 non-null  int64 \n",
      " 9   user_sentiment       29936 non-null  object\n",
      " 10  proc_reviews_text    29936 non-null  object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Details/dataset/SentimentbasedRecoEngine/final_data.csv', index_col=None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ad986e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26579\n",
       "0     3357\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'] = df['user_sentiment'].map({'Positive':1, 'Negative':0})\n",
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c62003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327ab1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"awesom love album . 's good . hip hop side current pop sound .. hype ! listen everyday gym ! give 5star rate way . metaphor crazi .\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'proc_reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad95289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['proc_reviews_text'], df['user_sentiment']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['proc_reviews_text'], df['user_sentiment'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a374db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffedd7a",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "1. TF-IDF Vectorizer \n",
    "2. Bag-of-Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3b15c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_model = tfidf_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17442a6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22452, 13290)\n"
     ]
    }
   ],
   "source": [
    "xtrain_tfi = tfidf_model.transform(xtrain)\n",
    "xtest_tfi  = tfidf_model.transform(xtest)\n",
    "\n",
    "xdf_tf = pd.DataFrame(xtrain_tfi.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "print(xdf_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa329e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f442af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow_model = bow_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64e27934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22452, 13076)\n"
     ]
    }
   ],
   "source": [
    "xtrain_bow = bow_model.transform(xtrain)\n",
    "xtest_bow  = bow_model.transform(xtest)\n",
    "\n",
    "xdf_bow = pd.DataFrame(xtrain_bow.toarray(), columns=bow_vectorizer.get_feature_names())\n",
    "print(xdf_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47965f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22452, 13290), (7484, 13290), (22452, 13076), (7484, 13076))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfi.shape, xtest_tfi.shape, xtrain_bow.shape, xtest_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1139c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54158010",
   "metadata": {},
   "source": [
    "## Class Imbalance Fix\n",
    "1. TF-IDF features\n",
    "2. Bag-of-Words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f4933d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_train_tf, y_train_tf = oversample.fit_resample(xtrain_tfi, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c9c10ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    19931\n",
       " 1    19931\n",
       " Name: user_sentiment, dtype: int64,\n",
       " (39862, 13290))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf.value_counts(), x_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae5bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea2a74b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_train_bw, y_train_bw = oversample.fit_resample(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c63333c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    19931\n",
       " 1    19931\n",
       " Name: user_sentiment, dtype: int64,\n",
       " (39862, 13076))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bw.value_counts(), x_train_bw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87f8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4326d1b",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "1. TF-IDF\n",
    "2. Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe8ccd",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58fadb3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(penalty=\"l2\", random_state=42, C=3.5)\n",
    "logreg1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train = logreg1.predict(x_train_tf)\n",
    "pred_test  = logreg1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22515775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     20838\n",
      "           1       0.92      0.96      0.94     19024\n",
      "\n",
      "    accuracy                           0.94     39862\n",
      "   macro avg       0.94      0.94      0.94     39862\n",
      "weighted avg       0.94      0.94      0.94     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.45      0.56      1396\n",
      "           1       0.88      0.97      0.92      6088\n",
      "\n",
      "    accuracy                           0.87      7484\n",
      "   macro avg       0.82      0.71      0.74      7484\n",
      "weighted avg       0.86      0.87      0.86      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "535cff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701229289150187 0.7087261708881014\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test, ytest), roc_auc_score(pred_test, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3da4d2",
   "metadata": {},
   "source": [
    "Old: Train accuracy: 0.8899546647578144 . Test accuracy: 0.8838659392049883\n",
    "Train AUC: 0.9449458052810008. Test AUC: 0.5255060352831941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268e720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cd4750c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(penalty=\"l2\", random_state=42, C=3.5)\n",
    "logreg2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train2 = logreg2.predict(x_train_bw)\n",
    "pred_test2  = logreg2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "531b0a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     20036\n",
      "           1       0.96      0.97      0.97     19826\n",
      "\n",
      "    accuracy                           0.97     39862\n",
      "   macro avg       0.97      0.97      0.97     39862\n",
      "weighted avg       0.97      0.97      0.97     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.51      0.58      1076\n",
      "           1       0.92      0.96      0.94      6408\n",
      "\n",
      "    accuracy                           0.89      7484\n",
      "   macro avg       0.79      0.73      0.76      7484\n",
      "weighted avg       0.88      0.89      0.89      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19d452b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892036344200962 0.7343457759584905\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test2, ytest), roc_auc_score(pred_test2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a66aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16968f09",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef875c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb1 = BernoulliNB()\n",
    "bnb1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_nb1 = bnb1.predict(x_train_tf)\n",
    "pred_test_nb1  = bnb1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2336a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76     15055\n",
      "           1       0.91      0.73      0.81     24807\n",
      "\n",
      "    accuracy                           0.79     39862\n",
      "   macro avg       0.79      0.81      0.79     39862\n",
      "weighted avg       0.82      0.79      0.79     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.29      0.30       935\n",
      "           1       0.90      0.91      0.91      6549\n",
      "\n",
      "    accuracy                           0.84      7484\n",
      "   macro avg       0.61      0.60      0.61      7484\n",
      "weighted avg       0.83      0.84      0.83      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_nb1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_nb1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d921ae9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835515766969535 0.6011723225083145\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_nb1, ytest), roc_auc_score(pred_test_nb1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af2fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3427a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb2 = BernoulliNB()\n",
    "bnb2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_nb2 = bnb2.predict(x_train_bw)\n",
    "pred_test_nb2  = bnb2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6cc555fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86     22807\n",
      "           1       0.78      0.91      0.84     17055\n",
      "\n",
      "    accuracy                           0.85     39862\n",
      "   macro avg       0.85      0.86      0.85     39862\n",
      "weighted avg       0.86      0.85      0.85     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.20      0.29      2029\n",
      "           1       0.76      0.92      0.83      5455\n",
      "\n",
      "    accuracy                           0.73      7484\n",
      "   macro avg       0.62      0.56      0.56      7484\n",
      "weighted avg       0.69      0.73      0.68      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_nb2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_nb2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c3c0fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272848743987173 0.5626644181820071\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_nb2, ytest), roc_auc_score(pred_test_nb2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e9fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5853b46d",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38ff411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier()\n",
    "xgb1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_xg1 = xgb1.predict(x_train_tf)\n",
    "pred_test_xg1  = xgb1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e0e9ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     19817\n",
      "           1       0.95      0.95      0.95     20045\n",
      "\n",
      "    accuracy                           0.95     39862\n",
      "   macro avg       0.95      0.95      0.95     39862\n",
      "weighted avg       0.95      0.95      0.95     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.50      0.55      1018\n",
      "           1       0.92      0.95      0.94      6466\n",
      "\n",
      "    accuracy                           0.89      7484\n",
      "   macro avg       0.76      0.72      0.74      7484\n",
      "weighted avg       0.88      0.89      0.88      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_xg1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_xg1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5399073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8874933190807055 0.7230084279443874\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_xg1, ytest), roc_auc_score(pred_test_xg1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929964d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fc94162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier()\n",
    "xgb2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_xg2 = xgb2.predict(x_train_bw)\n",
    "pred_test_xg2  = xgb2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9ed04d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     19063\n",
      "           1       0.98      0.94      0.96     20799\n",
      "\n",
      "    accuracy                           0.96     39862\n",
      "   macro avg       0.96      0.96      0.96     39862\n",
      "weighted avg       0.96      0.96      0.96     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.66      0.54       575\n",
      "           1       0.97      0.93      0.95      6909\n",
      "\n",
      "    accuracy                           0.91      7484\n",
      "   macro avg       0.71      0.80      0.74      7484\n",
      "weighted avg       0.93      0.91      0.92      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_xg2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_xg2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "41fe6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9127471940138963 0.7964924138017835\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_xg2, ytest), roc_auc_score(pred_test_xg2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbdc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a032bd5",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2ad05734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier()\n",
    "rf1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_rf1 = rf1.predict(x_train_tf)\n",
    "pred_test_rf1  = rf1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8847ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19933\n",
      "           1       1.00      1.00      1.00     19929\n",
      "\n",
      "    accuracy                           1.00     39862\n",
      "   macro avg       1.00      1.00      1.00     39862\n",
      "weighted avg       1.00      1.00      1.00     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.56      0.46       576\n",
      "           1       0.96      0.93      0.94      6908\n",
      "\n",
      "    accuracy                           0.90      7484\n",
      "   macro avg       0.68      0.75      0.70      7484\n",
      "weighted avg       0.92      0.90      0.91      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_rf1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_rf1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92f8f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981827899518974 0.74513195248665\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_rf1, ytest), roc_auc_score(pred_test_rf1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d7506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b72709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier()\n",
    "rf2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_rf2 = rf2.predict(x_train_bw)\n",
    "pred_test_rf2  = rf2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8f0df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19941\n",
      "           1       1.00      1.00      1.00     19921\n",
      "\n",
      "    accuracy                           1.00     39862\n",
      "   macro avg       1.00      1.00      1.00     39862\n",
      "weighted avg       1.00      1.00      1.00     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54       829\n",
      "           1       0.94      0.94      0.94      6655\n",
      "\n",
      "    accuracy                           0.90      7484\n",
      "   macro avg       0.74      0.74      0.74      7484\n",
      "weighted avg       0.90      0.90      0.90      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_rf2, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_rf2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f7206a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8972474612506681 0.7410540520700127\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_rf2, ytest), roc_auc_score(pred_test_rf2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b36ca83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f598e",
   "metadata": {},
   "source": [
    "{'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': 'auto',\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a70898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "771a4ac0",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "1. XGBoost with bag of words feature extraction performs best among all 4 models\n",
    "2. The model's performance can be improved using feature selection/dimensionality reduction on the data and hyperparameter optimization of the model\n",
    "\n",
    "#### Saving XGBoost Model and Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8ddd5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ddf33ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_filename = \"tfidf_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(tfidf_model, file)\n",
    "    \n",
    "# pkl_filename = \"bow_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(bow_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b34ee5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_filename = \"xgb_tf_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(xgb1, file)\n",
    "\n",
    "# pkl_filename = \"xgb_bow_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(xgb2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae1102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39d44428",
   "metadata": {},
   "source": [
    "## Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a376a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reviews(reviews_list):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a1e0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_file = \"tfidf_model.pkl\"\n",
    "with open(tf_model_file, 'rb') as file:\n",
    "    tf_model = pickle.load(file)\n",
    "    \n",
    "xgtf_model_file = \"xgb_tf_model.pkl\"\n",
    "with open(xgtf_model_file, 'rb') as file:\n",
    "    xgtf_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7e634f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2597574, 0.7402426]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some = tf_model.transform(xtrain[1200:1201].to_list())\n",
    "xgtf_model.predict_proba(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9db7d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15377    1\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[1200:1201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e8ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12800536",
   "metadata": {},
   "source": [
    "## Hyper-parameter Optimization:\n",
    "- XGBoost (Best Performing Model)\n",
    "- Prevent Overfitting (Using Random Search with Cross Validation & PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb62435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# max_depth = [int(x) for x in np.linspace(10, 100, num=10)]\n",
    "# max_depth.append(None)\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e8d5b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "#                           n_iter=30, scoring='accuracy', \n",
    "#                           cv=3, verbose=2, random_state=42, n_jobs=-1,\n",
    "#                           return_train_score=True)\n",
    "\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "656b5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b5c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
